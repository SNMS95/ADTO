{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural TO in 100 lines of code [JAX]\n",
    "\n",
    "# MBB beam BC\n",
    "# NN - from Keras\n",
    "# sigmoid + bisection - from scratch\n",
    "# Convoluion as filter\n",
    "# FEA - from 88 lines code\n",
    "# calculate compliance\n",
    "# Use adam optimizer\n",
    "# select free dofs and solve system\n",
    "# https://github.com/google/jax/discussions/16291 \n",
    "# https://github.com/google/jax/discussions/16248\n",
    "# https://github.com/google/jax/issues/22500\n",
    "# https://github.com/patrick-kidger/lineax/issues/24\n",
    "# https://github.com/google/jax/issues/13118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX not installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    import os\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "    from keras import layers\n",
    "    import keras\n",
    "except:\n",
    "    print(\"JAX not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretization\n",
    "Nx = 3\n",
    "Ny = 2\n",
    "volfrac = 0.5   # Volume fraction\n",
    "maxit = 75\n",
    "E0 = 1.0\n",
    "nu = 0.3\n",
    "E_min = 1e-9\n",
    "rmin=2\n",
    "penal = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEA - top71\n",
    "A11 = jnp.array([[12, 3, -6, -3], [3, 12, 3, 0], [-6, 3, 12, -3], [-3, 0, -3, 12]])\n",
    "A12 = jnp.array([[-6, -3, 0, 3], [-3, -6, -3, -6], [0, -3, -6, 3], [3, -6, 3, -6]])\n",
    "B11 = jnp.array([[-4, 3, -2, 9], [3, -4, -9, 4], [-2, -9, -4, -3], [9, 4, -3, -4]])\n",
    "B12 = jnp.array([[2, -3, 4, -9], [-3, 2, 9, -2], [4, 9, 2, 3], [-9, -2, 3, 2]])\n",
    "KE = 1/(1-nu**2)/24 * (jnp.block([[A11, A12], [A12.T, A11]]) + nu* jnp.block([[B11, B12], [B12.T, B11]]))\n",
    "nodeNrs = jnp.arange((1 + Nx) * (1 + Ny)).reshape((1 + Ny), (1 + Nx), order='F')\n",
    "cVec = (nodeNrs[0:-1, 0:-1]*2 + 2).reshape(Nx*Ny, 1, order='F').ravel()\n",
    "offsets = jax.numpy.array([0, 1, 2*Ny + 2, 2*Ny + 3, 2*Ny, 2*Ny + 1, -2, -1])\n",
    "cMat = cVec[:, None] + offsets\n",
    "iK = jnp.kron(cMat, jnp.ones((8, 1), dtype=jnp.int32)).T.ravel(order='F')\n",
    "jK = jnp.kron(cMat, jnp.ones((1, 8), dtype=jnp.int32)).ravel()\n",
    "Iar = jnp.concatenate([iK.reshape(-1,1), jK.reshape(-1,1)], axis=1)\n",
    "\n",
    "# MBB beam BC\n",
    "nDof = 2 * (Nx + 1) * (Ny + 1)\n",
    "lcDof = 1 # 2*nodeNrs[0, 0] - 1\n",
    "fixed1 = jnp.arange(0, 2 * (Ny + 1), 2) # left edge along x axis\n",
    "fixed2 = 2 * nodeNrs[-1, -1] + 1 # bottom right corner, along y axis\n",
    "fixed = jnp.union1d(fixed1, fixed2)\n",
    "F = jnp.zeros(nDof)\n",
    "F = F.at[lcDof].set(-1)\n",
    "F = F.at[fixed].set(0.0)\n",
    "free = jnp.setdiff1d(jnp.arange(nDof), fixed)\n",
    "\n",
    "# Convoluion as filter\n",
    "range_of_val = jnp.arange(-jnp.ceil(rmin) + 1, jnp.ceil(rmin))\n",
    "dx, dy = jnp.meshgrid(range_of_val, range_of_val)\n",
    "h = jnp.maximum(0, rmin - jnp.sqrt(dx**2 + dy**2)) # Cone filter (2D)\n",
    "Hs = jax.scipy.signal.convolve(jnp.ones((Ny, Nx)), h, mode='same') # Assuming dirichlet BC in matlab code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 2,  3,  8,  9,  6,  7,  0,  1],\n",
       "       [ 4,  5, 10, 11,  8,  9,  2,  3],\n",
       "       [ 8,  9, 14, 15, 12, 13,  6,  7],\n",
       "       [10, 11, 16, 17, 14, 15,  8,  9],\n",
       "       [14, 15, 20, 21, 18, 19, 12, 13],\n",
       "       [16, 17, 22, 23, 20, 21, 14, 15]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular TO pipeline\n",
    "from functools import partial\n",
    "from jax.experimental import sparse\n",
    "import optimistix as optx\n",
    "\n",
    "fixed_set = jnp.array(fixed)\n",
    "is_fixed_0 = jnp.isin(Iar[:, 0], fixed_set)\n",
    "is_fixed_1 = jnp.isin(Iar[:, 1], fixed_set) \n",
    "is_diag = Iar[:, 0] == Iar[:, 1]\n",
    "diag_mask = is_fixed_0 & is_diag\n",
    "offdiag_mask = is_fixed_0 | is_fixed_1\n",
    "offdiag_inds = offdiag_mask & ~is_diag\n",
    "\n",
    "# @partial(jax.jit)\n",
    "@jax.custom_vjp\n",
    "def find_comp(x, F):\n",
    "    xTilde = jnp.true_divide(jax.scipy.signal.convolve(x.reshape((Ny, Nx), order='F'), h, mode='same'), Hs).ravel(order='F')\n",
    "    sK = E_min + xTilde**penal * (E0 - E_min)\n",
    "    sK =(KE.reshape(-1, 1) * sK.reshape(1, -1)).ravel(order='F')\n",
    "    sK = sK.at[diag_mask].set(1.0)\n",
    "    sK = sK.at[offdiag_inds].set(0.0)\n",
    "    K = jax.experimental.sparse.BCOO((sK, Iar), shape=(2 * (Nx + 1) * (Ny + 1), 2 * (Nx + 1) * (Ny + 1)))\n",
    "    K = ((K + K.T) / 2.0).sum_duplicates(nse=len(Iar))\n",
    "    K_bcsr = sparse.BCSR.from_bcoo(K)\n",
    "    sol = sparse.linalg.spsolve(K_bcsr.data, K_bcsr.indices.astype(jnp.int32), K_bcsr.indptr, F, tol=1e-06, reorder=1)\n",
    "    ce = jnp.sum((sol[cMat]@KE) * sol[cMat], axis=1).reshape(Ny, Nx, order='F')\n",
    "    c_value = ((E_min + xTilde**penal * (E0 - E_min)).reshape(Ny, Nx, order='F') * ce).sum()\n",
    "    # c_value = jnp.dot(sol, F)\n",
    "    return c_value, xTilde, ce\n",
    "\n",
    "def find_comp_fwd(x, F):\n",
    "    c_value, xTilde, ce = find_comp(x, F)\n",
    "    return (c_value, xTilde), (xTilde, ce)\n",
    "\n",
    "def find_comp_bwd(res, g):\n",
    "    xPhys, ce = res\n",
    "    dc = -penal*(E0-E_min)*xPhys.reshape(Ny, Nx, order='F')**(penal-1)*ce#).ravel(order='F')  \n",
    "    dc = jax.scipy.signal.convolve(jnp.true_divide(dc, Hs), h, mode='same').ravel(order='F')\n",
    "    return dc.reshape(-1, 1)*g[0], jnp.zeros_like(F)\n",
    "\n",
    "find_comp.defvjp(find_comp_fwd, find_comp_bwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones(Nx * Ny) * volfrac\n",
    "xTilde = jnp.true_divide(jax.scipy.signal.convolve(x.reshape((Ny, Nx), order='F'), h, mode='same'), Hs).ravel(order='F')\n",
    "sK = E_min + xTilde**penal * (E0 - E_min)\n",
    "sK =(KE.reshape(-1, 1) * sK.reshape(1, -1)).ravel(order='F')\n",
    "sK = sK.at[diag_mask].set(1.0)\n",
    "sK = sK.at[offdiag_inds].set(0.0)\n",
    "K = jax.experimental.sparse.BCOO((sK, Iar), shape=(2 * (Nx + 1) * (Ny + 1), 2 * (Nx + 1) * (Ny + 1)))\n",
    "K = ((K + K.T) / 2.0).sum_duplicates(nse=len(Iar))\n",
    "K_bcsr = sparse.BCSR.from_bcoo(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.06181319,  0.        , -0.03777473, -0.00171703,\n",
       "         0.00686813,  0.02232143, -0.03090659,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.03777473,  0.        ,  0.06181319, -0.02232143,\n",
       "        -0.03090659,  0.00171703,  0.00686813,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.00171703,  0.        , -0.02232143,  0.12362637,\n",
       "         0.        ,  0.01373626,  0.        , -0.03777473,  0.00171703,\n",
       "        -0.03090659,  0.        ],\n",
       "       [ 0.        ,  0.00686813,  0.        , -0.03090659,  0.        ,\n",
       "         0.12362637,  0.        , -0.07554945, -0.00171703,  0.00686813,\n",
       "         0.02232143,  0.        ],\n",
       "       [ 0.        ,  0.02232143,  0.        ,  0.00171703,  0.01373626,\n",
       "         0.        ,  0.12362637,  0.        , -0.03090659, -0.02232143,\n",
       "        -0.03777473,  0.        ],\n",
       "       [ 0.        , -0.03090659,  0.        ,  0.00686813,  0.        ,\n",
       "        -0.07554945,  0.        ,  0.12362637, -0.02232143, -0.03090659,\n",
       "         0.00171703,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        , -0.03777473,\n",
       "        -0.00171703, -0.03090659, -0.02232143,  0.06181319,  0.02232143,\n",
       "         0.00686813,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.00171703,\n",
       "         0.00686813, -0.02232143, -0.03090659,  0.02232143,  0.06181319,\n",
       "        -0.00171703,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        , -0.03090659,\n",
       "         0.02232143, -0.03777473,  0.00171703,  0.00686813, -0.00171703,\n",
       "         0.06181319,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ]], dtype=float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural models and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_solver = optx.Bisection(rtol=1e-10, atol=1e-10) #optx.Newton(rtol=1e-8, atol=1e-8)\n",
    "\n",
    "class EnforceVolumeLayer(layers.Layer):\n",
    "    def __init__(self, volfrac):\n",
    "        super().__init__()\n",
    "        self.volfrac = volfrac\n",
    "\n",
    "    def call(self, x):\n",
    "        root_fn = lambda b, xTilde: jax.nn.sigmoid(b + xTilde).mean() - self.volfrac\n",
    "        b_opt = optx.root_find(root_fn, root_solver, 0.0, x, options=dict(lower=-100, upper=100)).value\n",
    "        return jax.nn.sigmoid(b_opt + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "def sine_init(shape, dtype=None, omega=30.0, seed=0, first=False):\n",
    "    limit = keras.ops.sqrt(6 / shape[0]) / omega\n",
    "    if first:\n",
    "        limit = 1 / shape[0]\n",
    "    return keras.random.uniform(shape, minval=-limit, maxval=limit, seed=seed)\n",
    "\n",
    "def get_siren_model(num_layers, units, omega0=30.0, seed=0):\n",
    "    first_init = partial(sine_init, seed=seed, first=True)\n",
    "    hidden_init = partial(sine_init, seed=seed, omega=omega0)\n",
    "    x = inputs = keras.Input(shape=(2,))\n",
    "    x = keras.ops.sin(layers.Dense(units, kernel_initializer=first_init)(x) * omega0)\n",
    "    for _ in range(num_layers-1):\n",
    "        x = keras.ops.sin(layers.Dense(units, kernel_initializer=hidden_init)(x) * omega0)\n",
    "    x = layers.Dense(1, kernel_initializer=hidden_init)(x)\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_mlp_model(units, num_layers):\n",
    "    x = inputs = keras.Input(shape=(2,))\n",
    "    for _ in range(num_layers):\n",
    "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(1)(x)\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_cnn_model(latent_size, Nx, Ny):\n",
    "    net = inputs = keras.Input(shape=(latent_size,), name=\"inp\")\n",
    "    filters = (Ny//8) * (Nx//8) * 32\n",
    "    net = keras.layers.Dense(filters, kernel_initializer=keras.initializers.orthogonal(\n",
    "        keras.ops.sqrt(max(filters / latent_size, 1))))(net)\n",
    "    net = keras.layers.Reshape([Ny//8, Nx//8, 32])(net)\n",
    "    for resize, filter in zip((1, 2, 2, 2, 1), (64, 32, 16, 8, 1)):\n",
    "        net = keras.layers.Activation(\"tanh\")(net)\n",
    "        net = keras.layers.UpSampling2D((resize, resize), interpolation='bilinear')(net)\n",
    "        net = keras.layers.LayerNormalization()(net)\n",
    "        net = keras.layers.Conv2D(\n",
    "            filter, (5, 5), kernel_initializer=keras.initializers.VarianceScaling, padding=\"same\")(net)\n",
    "    x = keras.layers.Reshape([Ny, Nx])(keras.layers.Flatten()(net))\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "def sine_init(shape, dtype=None, omega=30.0, seed=0, first=False):\n",
    "    limit = 1 / shape[0] if first else keras.ops.sqrt(6 / shape[0]) / omega\n",
    "    return keras.random.uniform(shape, minval=-limit, maxval=limit, seed=seed)\n",
    "\n",
    "def get_siren_model(num_layers, units, omega0=30.0, seed=0):\n",
    "    dense_layer = lambda init, x: keras.ops.sin(layers.Dense(units, kernel_initializer=init)(x) * omega0)\n",
    "    first_init = partial(sine_init, seed=seed, first=True)\n",
    "    hidden_init = partial(sine_init, seed=seed, omega=omega0)\n",
    "\n",
    "    x = inputs = keras.Input(shape=(2,))\n",
    "    x = dense_layer(first_init, x)\n",
    "    for _ in range(num_layers-1):\n",
    "        x = dense_layer(hidden_init, x)\n",
    "    x = layers.Dense(1, kernel_initializer=hidden_init)(x)\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def get_mlp_model(units, num_layers):\n",
    "    x = inputs = keras.Input(shape=(2,))\n",
    "    for _ in range(num_layers):\n",
    "        x = layers.Dense(units, activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    outputs = EnforceVolumeLayer(volfrac)(layers.Dense(1)(x))\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def get_cnn_model(latent_size, Nx, Ny):\n",
    "    def conv_block(net, resize, filters):\n",
    "        net = keras.layers.UpSampling2D((resize, resize), interpolation='bilinear')(keras.layers.Activation(\"tanh\")(net))\n",
    "        return keras.layers.Conv2D(filters, (5, 5), padding=\"same\")(keras.layers.LayerNormalization()(net))\n",
    "\n",
    "    filters = (Ny // 8) * (Nx // 8) * 32\n",
    "    net = inputs = keras.Input(shape=(latent_size,))\n",
    "    net = keras.layers.Dense(filters, kernel_initializer=keras.initializers.orthogonal(\n",
    "        keras.ops.sqrt(max(filters / latent_size, 1))))(net)\n",
    "    net = keras.layers.Reshape([Ny // 8, Nx // 8, 32])(net)\n",
    "\n",
    "    for resize, filter in zip((1, 2, 2, 2, 1), (64, 32, 16, 8, 1)):\n",
    "        net = conv_block(net, resize, filter)\n",
    "    \n",
    "    x = keras.layers.Reshape([Ny, Nx])(keras.layers.Flatten()(net))\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(10, Nx, Ny) #Siren(50, 3, 1, omega_0=100)#get_model(\n",
    "_ = model(jnp.ones((3, 10)))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1e-2)\n",
    "optimizer.build(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 3645.8521838725583\n",
      "Iteration: 1, Loss: 1156.509568038741\n",
      "Iteration: 2, Loss: 689.1192198859746\n",
      "Iteration: 3, Loss: 506.05865411793144\n",
      "Iteration: 4, Loss: 389.67617546186545\n",
      "Iteration: 5, Loss: 315.02134047345055\n",
      "Iteration: 6, Loss: 268.3876600712308\n",
      "Iteration: 7, Loss: 234.3679877613078\n",
      "Iteration: 8, Loss: 208.42679599542907\n",
      "Iteration: 9, Loss: 187.2744682104289\n",
      "Iteration: 10, Loss: 168.59279965615985\n",
      "Iteration: 11, Loss: 152.12821328602763\n",
      "Iteration: 12, Loss: 137.9967110738259\n",
      "Iteration: 13, Loss: 126.15800794834317\n",
      "Iteration: 14, Loss: 116.40933000888919\n",
      "Iteration: 15, Loss: 108.32760808638784\n",
      "Iteration: 16, Loss: 101.43561740262167\n",
      "Iteration: 17, Loss: 95.48549746423811\n",
      "Iteration: 18, Loss: 90.45252156874002\n",
      "Iteration: 19, Loss: 86.29023177573855\n",
      "Iteration: 20, Loss: 82.79135717966787\n",
      "Iteration: 21, Loss: 79.70512159837207\n",
      "Iteration: 22, Loss: 76.88546850475596\n",
      "Iteration: 23, Loss: 74.29979534954127\n",
      "Iteration: 24, Loss: 71.93177404949162\n",
      "Iteration: 25, Loss: 69.76696718614454\n",
      "Iteration: 26, Loss: 67.79995731739486\n",
      "Iteration: 27, Loss: 65.9882110019739\n",
      "Iteration: 28, Loss: 64.35397851909097\n",
      "Iteration: 29, Loss: 62.894875072828256\n",
      "Iteration: 30, Loss: 61.56520593958007\n",
      "Iteration: 31, Loss: 60.33366293139322\n",
      "Iteration: 32, Loss: 59.187818810283815\n",
      "Iteration: 33, Loss: 58.13852465290324\n",
      "Iteration: 34, Loss: 57.18961483033176\n",
      "Iteration: 35, Loss: 56.33026528653386\n",
      "Iteration: 36, Loss: 55.5688641140173\n",
      "Iteration: 37, Loss: 54.87886463276898\n",
      "Iteration: 38, Loss: 54.23850494464392\n",
      "Iteration: 39, Loss: 53.632913367386806\n",
      "Iteration: 40, Loss: 53.081378699598886\n",
      "Iteration: 41, Loss: 52.56744859678163\n",
      "Iteration: 42, Loss: 52.103218226444724\n",
      "Iteration: 43, Loss: 51.69826724156471\n",
      "Iteration: 44, Loss: 51.30749519116998\n",
      "Iteration: 45, Loss: 50.99946559624151\n",
      "Iteration: 46, Loss: 50.63563446247498\n",
      "Iteration: 47, Loss: 50.4446612353326\n",
      "Iteration: 48, Loss: 50.088330846047086\n",
      "Iteration: 49, Loss: 50.054805326615785\n",
      "Iteration: 50, Loss: 49.91541588814842\n",
      "Iteration: 51, Loss: 49.44837504276778\n",
      "Iteration: 52, Loss: 49.288280157242106\n",
      "Iteration: 53, Loss: 49.04728421238829\n",
      "Iteration: 54, Loss: 49.17457856511108\n",
      "Iteration: 55, Loss: 48.93788562797009\n",
      "Iteration: 56, Loss: 48.622574373855976\n",
      "Iteration: 57, Loss: 49.431529242708976\n",
      "Iteration: 58, Loss: 49.77218708841514\n",
      "Iteration: 59, Loss: 48.22366996777467\n",
      "Iteration: 60, Loss: 48.38061174125218\n",
      "Iteration: 61, Loss: 48.49833075358732\n",
      "Iteration: 62, Loss: 48.235799720244444\n",
      "Iteration: 63, Loss: 47.96906123087825\n",
      "Iteration: 64, Loss: 47.76186224394948\n",
      "Iteration: 65, Loss: 47.851669358365314\n",
      "Iteration: 66, Loss: 47.52021019234079\n",
      "Iteration: 67, Loss: 47.56156425158345\n",
      "Iteration: 68, Loss: 47.366990159045514\n",
      "Iteration: 69, Loss: 47.255315012723955\n",
      "Iteration: 70, Loss: 47.41481109627536\n",
      "Iteration: 71, Loss: 47.13423796613493\n",
      "Iteration: 72, Loss: 46.96604743611054\n",
      "Iteration: 73, Loss: 46.90399930957487\n",
      "Iteration: 74, Loss: 46.75809721054475\n"
     ]
    }
   ],
   "source": [
    "# for cnn \n",
    "x = jnp.ones((1, 10))\n",
    "train_vars = model.trainable_variables\n",
    "non_train_vars = model.non_trainable_variables\n",
    "\n",
    "def compute_loss_updates(train_vars, non_train_vars, x):\n",
    "    output, non_train_vars = model.stateless_call(train_vars, non_train_vars, x)\n",
    "    c, design = find_comp(output.reshape(-1, 1, order='F'), F)\n",
    "    return c, (non_train_vars, design)\n",
    "\n",
    "grad_fn = jax.value_and_grad(compute_loss_updates, has_aux=True)\n",
    "\n",
    "@jax.jit\n",
    "def train(state, x):\n",
    "    train_vars, non_train_vars, opt_vars, _ = state\n",
    "    (loss, (non_train_vars, design)), grad = grad_fn(train_vars, non_train_vars, x)\n",
    "    train_vars, opt_vars = optimizer.stateless_apply(opt_vars, grad, train_vars)\n",
    "    return loss, (train_vars, non_train_vars, opt_vars, design)\n",
    "\n",
    "state = ([w.value for w in train_vars], non_train_vars, optimizer.variables, None)\n",
    "for i in range(maxit):\n",
    "    loss, state = train(state, x)\n",
    "    print(f\"Iteration: {i}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get network input (nEl, 2)\n",
    "# Create a grid of center coordinates\n",
    "x_centers = jnp.linspace(-1 + 1/Nx, 1 - 1/Nx, Nx)\n",
    "y_centers = jnp.linspace(-1 + 1/Ny, 1 - 1/Ny, Ny)\n",
    "\n",
    "# Create a meshgrid from x and y centers\n",
    "x_grid, y_grid = jnp.meshgrid(x_centers, y_centers, indexing='ij')\n",
    "\n",
    "# Stack the grid coordinates into a single array of shape (Nx * Ny, 2)\n",
    "x = jnp.column_stack([x_grid.ravel(), jnp.flip(y_grid).ravel()])\n",
    "\n",
    "train_vars = model.trainable_variables\n",
    "non_train_vars = model.non_trainable_variables\n",
    "\n",
    "def compute_loss_updates(train_vars, non_train_vars, x):\n",
    "    output, non_train_vars = model.stateless_call(train_vars, non_train_vars, x)\n",
    "    c, design = find_comp(output, F)\n",
    "    return c, (non_train_vars, design)\n",
    "\n",
    "grad_fn = jax.value_and_grad(compute_loss_updates, has_aux=True)\n",
    "\n",
    "@jax.jit\n",
    "def train(state, x):\n",
    "    train_vars, non_train_vars, opt_vars, _ = state\n",
    "    (loss, (non_train_vars, design)), grad = grad_fn(train_vars, non_train_vars, x)\n",
    "    train_vars, opt_vars = optimizer.stateless_apply(opt_vars, grad, train_vars)\n",
    "    return loss, (train_vars, non_train_vars, opt_vars, design)\n",
    "\n",
    "state = ([w.value for w in train_vars], non_train_vars, optimizer.variables, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 1887.1529444283115\n",
      "Iteration: 1, Loss: 963.465929901738\n",
      "Iteration: 2, Loss: 637.2813199689981\n",
      "Iteration: 3, Loss: 466.6914633898561\n",
      "Iteration: 4, Loss: 370.1885323720079\n",
      "Iteration: 5, Loss: 311.74368493501555\n",
      "Iteration: 6, Loss: 274.9968351924058\n",
      "Iteration: 7, Loss: 249.06418671611775\n",
      "Iteration: 8, Loss: 227.6089865494722\n",
      "Iteration: 9, Loss: 209.10327593704585\n",
      "Iteration: 10, Loss: 193.34800014974974\n",
      "Iteration: 11, Loss: 179.79700418208625\n",
      "Iteration: 12, Loss: 168.02203391547093\n",
      "Iteration: 13, Loss: 157.5612044555362\n",
      "Iteration: 14, Loss: 148.2211894000748\n",
      "Iteration: 15, Loss: 139.78693416531002\n",
      "Iteration: 16, Loss: 131.96705428543623\n",
      "Iteration: 17, Loss: 124.66474034700838\n",
      "Iteration: 18, Loss: 117.93963753129135\n",
      "Iteration: 19, Loss: 111.88095242059694\n",
      "Iteration: 20, Loss: 106.49124224426184\n",
      "Iteration: 21, Loss: 101.66830534763663\n",
      "Iteration: 22, Loss: 97.30355913239134\n",
      "Iteration: 23, Loss: 93.34673290154056\n",
      "Iteration: 24, Loss: 89.76023944201731\n",
      "Iteration: 25, Loss: 86.46695988540034\n",
      "Iteration: 26, Loss: 83.40939583392439\n",
      "Iteration: 27, Loss: 80.61528924572653\n",
      "Iteration: 28, Loss: 78.09866172559715\n",
      "Iteration: 29, Loss: 75.81679196351446\n",
      "Iteration: 30, Loss: 73.72980325360857\n",
      "Iteration: 31, Loss: 71.81810572123831\n",
      "Iteration: 32, Loss: 70.06147287985604\n",
      "Iteration: 33, Loss: 68.43756419573498\n",
      "Iteration: 34, Loss: 66.9382915446419\n",
      "Iteration: 35, Loss: 65.56893880363359\n",
      "Iteration: 36, Loss: 64.32606914982856\n",
      "Iteration: 37, Loss: 63.190257052233\n",
      "Iteration: 38, Loss: 62.128660854201755\n",
      "Iteration: 39, Loss: 61.115389324214675\n",
      "Iteration: 40, Loss: 60.14811735192904\n",
      "Iteration: 41, Loss: 59.2355324295218\n",
      "Iteration: 42, Loss: 58.37474835598387\n",
      "Iteration: 43, Loss: 57.558582269395174\n",
      "Iteration: 44, Loss: 56.78676884191439\n",
      "Iteration: 45, Loss: 56.06029396734643\n",
      "Iteration: 46, Loss: 55.3901002864039\n",
      "Iteration: 47, Loss: 54.79192064419041\n",
      "Iteration: 48, Loss: 54.27955585814317\n",
      "Iteration: 49, Loss: 53.77181208997422\n",
      "Iteration: 50, Loss: 53.32165783284392\n",
      "Iteration: 51, Loss: 52.934071894124685\n",
      "Iteration: 52, Loss: 52.52277294986446\n",
      "Iteration: 53, Loss: 52.16730735125097\n",
      "Iteration: 54, Loss: 51.892746281668536\n",
      "Iteration: 55, Loss: 51.53661669557377\n",
      "Iteration: 56, Loss: 51.250923861280896\n",
      "Iteration: 57, Loss: 51.03324021647012\n",
      "Iteration: 58, Loss: 50.73829405979489\n",
      "Iteration: 59, Loss: 50.54019392654464\n",
      "Iteration: 60, Loss: 50.29545639592078\n",
      "Iteration: 61, Loss: 50.16077778348478\n",
      "Iteration: 62, Loss: 49.953208096199276\n",
      "Iteration: 63, Loss: 49.73139821597218\n",
      "Iteration: 64, Loss: 49.618807632588464\n",
      "Iteration: 65, Loss: 49.35226264894253\n",
      "Iteration: 66, Loss: 49.384423291115105\n",
      "Iteration: 67, Loss: 49.233043133048426\n",
      "Iteration: 68, Loss: 48.97695632715606\n",
      "Iteration: 69, Loss: 48.783863362965214\n",
      "Iteration: 70, Loss: 48.5703299715275\n",
      "Iteration: 71, Loss: 48.398382621629665\n",
      "Iteration: 72, Loss: 48.15985536374857\n",
      "Iteration: 73, Loss: 47.82496079843563\n",
      "Iteration: 74, Loss: 47.31148415751238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x32c653f70>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(maxit):\n",
    "    loss, state = train(state, x)\n",
    "    print(f\"Iteration: {i}, Loss: {loss}\")\n",
    "\n",
    "des = state[-1].reshape((Ny, Nx), order='F')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(des, cmap='Greys')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gradients\n",
    "from jax.test_util import check_grads\n",
    "\n",
    "def loss_fn(x):\n",
    "    return find_comp(x, F)[0]\n",
    "\n",
    "check_grads(loss_fn, (jax.random.uniform(jax.random.PRNGKey(2), (Ny*Nx, 1)),), order=1, modes=['rev'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x329ffe2e0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check filter \n",
    "# Create a black square [with values 1] and set everything else to 0\n",
    "# Try th convolution filter on it\n",
    "# Check visually if the filter is working as expected\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "nx = 16\n",
    "ny = 12\n",
    "init_design = jnp.zeros((nx*ny, 1))\n",
    "# make a black square along the x direction at the center\n",
    "init_design_reshaped = init_design.reshape(ny, nx, order='F')\n",
    "init_design_reshaped = init_design_reshaped.at[ny//2-2:ny//2+2, :].set(1).ravel(order='F')\n",
    "plt.imshow(init_design_reshaped.reshape(ny, nx, order='F'), cmap='Greys')\n",
    "plt.colorbar()\n",
    "# # Apply the filter\n",
    "Hs = jax.scipy.signal.convolve(jnp.ones((ny, nx)), h, mode='same') # Assuming dirichlet BC in matlab code\n",
    "xTilde = jnp.true_divide(jax.scipy.signal.convolve(init_design_reshaped.reshape((ny, nx), order='F'), h, mode='same'), Hs).ravel(order='F')\n",
    "# show the filtered image\n",
    "plt.imshow(xTilde.reshape(ny, nx, order='F'), cmap='Greys')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, jax, jax.numpy as jnp, matplotlib.pyplot as plt\n",
    "from jax.experimental import sparse\n",
    "import keras, optimistix as optx\n",
    "from functools import partial\n",
    "from keras import layers\n",
    "\n",
    "# Setup\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "Nx, Ny, volfrac, maxit = 64, 64, 0.3, 100\n",
    "E0, nu, E_min, rmin, penal = 1.0, 0.3, 1e-9, 2, 3\n",
    "A11 = jnp.array([[12, 3, -6, -3], [3, 12, 3, 0], [-6, 3, 12, -3], [-3, 0, -3, 12]])\n",
    "A12 = jnp.array([[-6, -3, 0, 3], [-3, -6, -3, -6], [0, -3, -6, 3], [3, -6, 3, -6]])\n",
    "B11 = jnp.array([[-4, 3, -2, 9], [3, -4, -9, 4], [-2, -9, -4, -3], [9, 4, -3, -4]])\n",
    "B12 = jnp.array([[2, -3, 4, -9], [-3, 2, 9, -2], [4, 9, 2, 3], [-9, -2, 3, 2]])\n",
    "KE = (1/(1-nu**2)/24 * (jnp.block([[A11, A12], [A12.T, A11]]) + nu * jnp.block([[B11, B12], [B12.T, B11]])))\n",
    "nodeNrs = jnp.arange((1 + Nx) * (1 + Ny)).reshape((1 + Ny), (1 + Nx), order='F')\n",
    "cVec, offsets = (nodeNrs[:-1, :-1]*2 + 2).reshape(Nx*Ny, 1, order='F').ravel(), jnp.array([0, 1, 2*Ny + 2, 2*Ny + 3, 2*Ny, 2*Ny + 1, -2, -1])\n",
    "cMat, Iar = cVec[:, None] + offsets, jnp.concatenate([jnp.kron(cVec[:, None] + offsets, jnp.ones((8, 1), dtype=jnp.int32)).T.ravel(order='F').reshape(-1, 1), jnp.kron(cVec[:, None] + offsets, jnp.ones((1, 8), dtype=jnp.int32)).ravel().reshape(-1, 1)], axis=1)\n",
    "nDof, lcDof = 2 * (Nx + 1) * (Ny + 1), 1\n",
    "fixed = jnp.union1d(jnp.arange(0, 2 * (Ny + 1), 2), 2 * nodeNrs[-1, -1] + 1)\n",
    "F, free = jnp.zeros(nDof).at[lcDof].set(-1).at[fixed].set(0.0), jnp.setdiff1d(jnp.arange(nDof), fixed)\n",
    "dx, dy = jnp.meshgrid(jnp.arange(-jnp.ceil(rmin) + 1, jnp.ceil(rmin)), jnp.arange(-jnp.ceil(rmin) + 1, jnp.ceil(rmin)))\n",
    "h, Hs = jnp.maximum(0, rmin - jnp.sqrt(dx**2 + dy**2)), jax.scipy.signal.convolve(jnp.ones((Ny, Nx)), h, mode='same')\n",
    "is_fixed_0, is_fixed_1 = jnp.isin(Iar[:, 0], jnp.array(fixed)), jnp.isin(Iar[:, 1], jnp.array(fixed))\n",
    "diag_mask, offdiag_inds = is_fixed_0 & (Iar[:, 0] == Iar[:, 1]), (is_fixed_0 | is_fixed_1) & ~(Iar[:, 0] == Iar[:, 1])\n",
    "\n",
    "# Black-box calculation of compliance\n",
    "@jax.custom_vjp\n",
    "def find_comp(x, F):\n",
    "    xTilde = jax.scipy.signal.convolve(x.reshape((Ny, Nx), order='F'), h, mode='same').ravel(order='F') / Hs\n",
    "    sK = (KE.reshape(-1, 1) * (E_min + xTilde**penal * (E0 - E_min)).reshape(1, -1)).ravel(order='F').at[diag_mask].set(1.0).at[offdiag_inds].set(0.0)\n",
    "    K = sparse.BCOO((sK, Iar), shape=(2*(Nx+1)*(Ny+1), 2*(Nx+1)*(Ny+1))).sum_duplicates(nse=len(Iar))\n",
    "    sol = sparse.linalg.spsolve(sparse.BCSR.from_bcoo(K).data, K.indices.astype(jnp.int32), K.indptr, F, tol=1e-06, reorder=1)\n",
    "    ce, c_value = jnp.sum((sol[cMat]@KE) * sol[cMat], axis=1).reshape(Ny, Nx, order='F'), jnp.sum((E_min + xTilde**penal * (E0 - E_min)).reshape(Ny, Nx, order='F') * ce)\n",
    "    return c_value, xTilde, ce\n",
    "\n",
    "def find_comp_fwd(x, F): c_value, xTilde, ce = find_comp(x, F); return (c_value, xTilde), (xTilde, ce)\n",
    "def find_comp_bwd(res, g): return (-penal*(E0-E_min)*res[0].reshape(Ny, Nx, order='F')**(penal-1)*res[1]).ravel(order='F') / Hs * g[0], jnp.zeros_like(F)\n",
    "find_comp.defvjp(find_comp_fwd, find_comp_bwd)\n",
    "\n",
    "# Neural network models\n",
    "root_solver = optx.Bisection(rtol=1e-10, atol=1e-10)\n",
    "class EnforceVolumeLayer(layers.Layer):\n",
    "    def __init__(self, volfrac): super().__init__(); self.volfrac = volfrac\n",
    "    def call(self, x): return jax.nn.sigmoid(optx.root_find(lambda b, xTilde: jax.nn.sigmoid(b + xTilde).mean() - self.volfrac, root_solver, 0.0, x, options=dict(lower=-100, upper=100)).value + x)\n",
    "\n",
    "def sine_init(shape, dtype=None, omega=30.0, seed=0, first=False): limit = 1/shape[0] if first else keras.ops.sqrt(6/shape[0])/omega; return keras.random.uniform(shape, minval=-limit, maxval=limit, seed=seed)\n",
    "\n",
    "def get_model(model_type, num_layers, units, latent_size=10):\n",
    "    def dense_layer(init, x): return keras.ops.sin(layers.Dense(units, kernel_initializer=init)(x) * omega0)\n",
    "    if model_type == 'siren':\n",
    "        first_init, hidden_init, omega0 = partial(sine_init, seed=0, first=True), partial(sine_init, seed=0, omega=30.0), 30.0\n",
    "        x = inputs = keras.Input(shape=(2,))\n",
    "        x = dense_layer(first_init, x)\n",
    "        for _ in range(num_layers - 1): x = dense_layer(hidden_init, x)\n",
    "        x = layers.Dense(1, kernel_initializer=hidden_init)(x)\n",
    "    elif model_type == 'mlp':\n",
    "        x = inputs = keras.Input(shape=(2,))\n",
    "        for _ in range(num_layers): x = layers.Dense(units, activation=\"relu\")(x); x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dense(1)(x)\n",
    "    elif model_type == 'cnn':\n",
    "        def conv_block(net, resize, filters): return keras.layers.Conv2D(filters, (5, 5), padding=\"same\")(keras.layers.LayerNormalization()(keras.layers.UpSampling2D((resize, resize), interpolation='bilinear')(keras.layers.Activation(\"tanh\")(net))))\n",
    "        filters, x = (Ny // 8) * (Nx // 8) * 32, inputs = keras.Input(shape=(latent_size,))\n",
    "        net = keras.layers.Reshape([Ny // 8, Nx // 8, 32])(keras.layers.Dense(filters, kernel_initializer=keras.initializers.orthogonal(keras.ops.sqrt(max(filters / latent_size, 1))))(x))\n",
    "        for resize, filter in zip((1, 2, 2, 2, 1), (64, 32, 16, 8, 1)): net = conv_block(net, resize, filter)\n",
    "        x = keras.layers.Reshape([Ny, Nx])(keras.layers.Flatten()(net))\n",
    "    outputs = EnforceVolumeLayer(volfrac)(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Optimization\n",
    "model = get_model('cnn', 0, 0, 10)  # Choose 'siren', 'mlp', or 'cnn' with parameters\n",
    "_ = model(jnp.ones((3, 10)))  # Initialize the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2, clipnorm=1e-2)\n",
    "optimizer.build(model.trainable_variables)\n",
    "state = ([w.value for w in model.trainable_variables], model.non_trainable_variables, optimizer.variables, None)\n",
    "train_vars, non_train_vars = model.trainable_variables, model.non_trainable_variables\n",
    "\n",
    "def compute_loss_updates(train_vars, non_train_vars, x):\n",
    "    output, non_train_vars = model.stateless_call(train_vars, non_train_vars, x)\n",
    "    c, design = find_comp(output.reshape(-1, 1, order='F'), F)\n",
    "    return c, (non_train_vars, design)\n",
    "\n",
    "grad_fn = jax.value_and_grad(compute_loss_updates, has_aux=True)\n",
    "\n",
    "@jax.jit\n",
    "def train(state, x):\n",
    "    train_vars, non_train_vars, opt_vars, _ = state\n",
    "    (loss, (non_train_vars, design)), grad = grad_fn(train_vars, non_train_vars, x)\n",
    "    train_vars, opt_vars = optimizer.stateless_apply(opt_vars, grad, train_vars)\n",
    "    return loss, (train_vars, non_train_vars, opt_vars, design)\n",
    "\n",
    "for i in range(maxit):\n",
    "    loss, state = train(state, jnp.ones((1, 10)))\n",
    "    print(f\"Iteration: {i}, Loss: {loss}\")\n",
    "\n",
    "# Display result\n",
    "plt.imshow(state[-1].reshape((Ny, Nx), order='F'), cmap='Greys')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit function theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "# @jax.custom_vjp(nondiff_argnums=(0,2,3,4,5))\n",
    "@partial(jax.custom_vjp, nondiff_argnums=(0,2,3,4,5))\n",
    "def custom_bisection_alg(root_fn, net_out, lb, ub, max_iter=100, tol=1e-10):\n",
    "    for _ in range(max_iter):\n",
    "        mid = (lb + ub) / 2\n",
    "        mid_val = root_fn(mid, net_out)\n",
    "        if mid_val > 0:\n",
    "            ub = mid\n",
    "        else:\n",
    "            lb = mid\n",
    "        if jnp.abs(mid_val) < tol:\n",
    "            break\n",
    "    return mid\n",
    "\n",
    "def custom_bisection_alg_fwd(root_fn, net_out, lb, ub, max_iter=100, tol=1e-10):\n",
    "    b_opt = custom_bisection_alg(root_fn, net_out, lb, ub, max_iter, tol)\n",
    "    res = net_out, b_opt\n",
    "    return b_opt, res\n",
    "\n",
    "def custom_bisection_alg_bwd(root_fn, lb, ub, max_iter, tol, res, g):\n",
    "    design, b_opt = res\n",
    "    df_db, df_ddes = jax.grad(root_fn, (0, 1))(b_opt, design)\n",
    "    vJP = -g*df_ddes / df_db\n",
    "    return (vJP.reshape(design.shape), )\n",
    "\n",
    "custom_bisection_alg.defvjp(custom_bisection_alg_fwd, custom_bisection_alg_bwd) \n",
    "\n",
    "# Test\n",
    "def root_fn(b, design):\n",
    "    return jax.nn.sigmoid(b + design).mean() - volfrac\n",
    "\n",
    "\n",
    "volfrac = 0.4\n",
    "Nx= Ny = 10\n",
    "\n",
    "design = jax.random.uniform(jax.random.PRNGKey(0), (Nx*Ny, 1))\n",
    "# b = jax.jit(custom_bisection_alg, static_argnums=(0,2,3,4,5))(root_fn, design, -100, 100)\n",
    "# jax.jacobian(lambda des: custom_bisection_alg(root_fn, des, -100, 100), 0)(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.00866813],\n",
       "       [-0.01058955],\n",
       "       [-0.01056763],\n",
       "       [-0.01014607],\n",
       "       [-0.00919227],\n",
       "       [-0.01056041],\n",
       "       [-0.01014276],\n",
       "       [-0.0097378 ],\n",
       "       [-0.01012735],\n",
       "       [-0.00970594],\n",
       "       [-0.00897526],\n",
       "       [-0.008963  ],\n",
       "       [-0.01058248],\n",
       "       [-0.01055084],\n",
       "       [-0.00971596],\n",
       "       [-0.01058069],\n",
       "       [-0.00943302],\n",
       "       [-0.00933133],\n",
       "       [-0.00866977],\n",
       "       [-0.01024209],\n",
       "       [-0.0095407 ],\n",
       "       [-0.01060871],\n",
       "       [-0.01033217],\n",
       "       [-0.01050381],\n",
       "       [-0.0101674 ],\n",
       "       [-0.01039877],\n",
       "       [-0.00990289],\n",
       "       [-0.0094158 ],\n",
       "       [-0.01051008],\n",
       "       [-0.00871122],\n",
       "       [-0.01058877],\n",
       "       [-0.00867018],\n",
       "       [-0.01005409],\n",
       "       [-0.01049171],\n",
       "       [-0.00974384],\n",
       "       [-0.01035709],\n",
       "       [-0.01032987],\n",
       "       [-0.00882012],\n",
       "       [-0.01056494],\n",
       "       [-0.00932875],\n",
       "       [-0.0103867 ],\n",
       "       [-0.00967012],\n",
       "       [-0.010227  ],\n",
       "       [-0.01060135],\n",
       "       [-0.0106076 ],\n",
       "       [-0.01058264],\n",
       "       [-0.01009211],\n",
       "       [-0.00900834],\n",
       "       [-0.00918422],\n",
       "       [-0.01058158],\n",
       "       [-0.01028962],\n",
       "       [-0.01044312],\n",
       "       [-0.010608  ],\n",
       "       [-0.01027568],\n",
       "       [-0.00953941],\n",
       "       [-0.00973531],\n",
       "       [-0.01015859],\n",
       "       [-0.01060384],\n",
       "       [-0.01024751],\n",
       "       [-0.00942953],\n",
       "       [-0.0104438 ],\n",
       "       [-0.0106073 ],\n",
       "       [-0.01007155],\n",
       "       [-0.01060258],\n",
       "       [-0.01047016],\n",
       "       [-0.01060849],\n",
       "       [-0.01043109],\n",
       "       [-0.00998062],\n",
       "       [-0.00979153],\n",
       "       [-0.01060831],\n",
       "       [-0.00962538],\n",
       "       [-0.01047107],\n",
       "       [-0.01059829],\n",
       "       [-0.01032813],\n",
       "       [-0.01032439],\n",
       "       [-0.00937188],\n",
       "       [-0.01019228],\n",
       "       [-0.01060726],\n",
       "       [-0.00887895],\n",
       "       [-0.01017255],\n",
       "       [-0.01059237],\n",
       "       [-0.01038929],\n",
       "       [-0.01003875],\n",
       "       [-0.00964622],\n",
       "       [-0.00996537],\n",
       "       [-0.01007938],\n",
       "       [-0.00990985],\n",
       "       [-0.01050031],\n",
       "       [-0.00912778],\n",
       "       [-0.01042139],\n",
       "       [-0.00888974],\n",
       "       [-0.00874732],\n",
       "       [-0.00932131],\n",
       "       [-0.01003799],\n",
       "       [-0.01050176],\n",
       "       [-0.00939098],\n",
       "       [-0.00935494],\n",
       "       [-0.01060135],\n",
       "       [-0.01059948],\n",
       "       [-0.00990331]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(lambda des: custom_bisection_alg(root_fn, des, -100, 100), 0)(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metatop_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
