{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5632625f",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/SNMS95/ADTO/blob/main/examples/TO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28216075",
      "metadata": {
        "id": "28216075"
      },
      "outputs": [],
      "source": [
        "# === User-defined Settings for Topology Optimization ===\n",
        "\n",
        "ML_framework_to_use = \"torch\"  # Choose ML backend: \"torch\" or \"jax\"\n",
        "\n",
        "# Grid resolution (number of finite elements in x and y directions)\n",
        "Nx = 96                       # Number of elements along x-axis\n",
        "Ny = 64                       # Number of elements along y-axis\n",
        "\n",
        "# Material properties\n",
        "E0 = 1.0                     # Young's modulus of solid material\n",
        "Emin = 1e-9                  # Young's modulus of void\n",
        "nu = 0.3                     # Poisson's ratio\n",
        "\n",
        "# Filter and penalization\n",
        "rmin = 2.0                   # Radius for density filter\n",
        "penal = 3.0                  # SIMP penalization factor\n",
        "\n",
        "# Optimization control\n",
        "max_iterations = 30         # Number of optimization steps\n",
        "volfrac = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbc90b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffbc90b8",
        "outputId": "b59d9342-7f71-4a6b-d588-5a55448320b3"
      },
      "outputs": [],
      "source": [
        "# # Sanity checks\n",
        "assert ML_framework_to_use in [\"jax\", \"torch\"]\n",
        "assert penal >= 1.0\n",
        "assert rmin >= 1.0\n",
        "\n",
        "# Check if in Colab and setup accordingly\n",
        "try:\n",
        "    import google.colab\n",
        "    import os\n",
        "    import sys\n",
        "    \n",
        "    if not os.path.exists('ADTO'):\n",
        "        !git clone https://github.com/SNMS95/ADTO.git\n",
        "    \n",
        "    %cd ADTO\n",
        "    !pip install -e .\n",
        "    \n",
        "    # Add src directory to path\n",
        "    repo_path = '/content/ADTO/src'\n",
        "    if repo_path not in sys.path:\n",
        "        sys.path.insert(0, repo_path)\n",
        "    \n",
        "    print(\"ðŸ”§ Colab setup complete\")\n",
        "except:\n",
        "    print(\"ðŸ”§ Running locally\")\n",
        "\n",
        "# Set backend before importing anything else\n",
        "import os\n",
        "os.environ[\"ML_BACKEND\"] = ML_framework_to_use\n",
        "\n",
        "# Now safe to import\n",
        "from adto import (\n",
        "    setup_fea_problem,\n",
        "    solve,\n",
        "    reduce_K,\n",
        "    assemble_stiffness_matrix_parts,\n",
        "    apply_density_filter,\n",
        "    optimality_criteria\n",
        ")\n",
        "\n",
        "if ML_framework_to_use == \"jax\":\n",
        "    import jax\n",
        "    import jax.numpy as jnp\n",
        "else:\n",
        "    import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f575b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simp_and_reduced_solve(physical_densities, problem_data):\n",
        "    # Compute compliance\n",
        "    E = problem_data['E_min'] + physical_densities**penal * \\\n",
        "        (problem_data['E0'] - problem_data['E_min'])\n",
        "    iK, jK, sK = assemble_stiffness_matrix_parts(E, problem_data)\n",
        "    free_dofs = problem_data['free']\n",
        "    f = problem_data['F']\n",
        "    f_f = f[free_dofs]\n",
        "    # reduce K to K_f\n",
        "    iK_f, jK_f, sK_f = reduce_K(iK, jK, sK, free_dofs, len(f))\n",
        "    # Solve system\n",
        "    if ML_framework_to_use == \"torch\":\n",
        "        # Torch needs tensor inputs to be passed since we provide gradients w.r.t the force vector as well in teh custom VJP rule\n",
        "        u_f = solve(sK_f, iK_f, jK_f, torch.Tensor(f_f))\n",
        "    else:\n",
        "        u_f = solve(sK_f, iK_f, jK_f, f_f)\n",
        "    return u_f\n",
        "\n",
        "\n",
        "def run_with_jax_backend(problem_data, rho_init=None, max_iterations=100):\n",
        "    \"\"\"Training example with JAX backend\"\"\"\n",
        "    print(\"Training with JAX backend...\")\n",
        "\n",
        "    # Initialize design variables\n",
        "    if rho_init is None:\n",
        "        rho_init = jnp.ones((problem_data['Ny'], problem_data['Nx'])) * volfrac  # Initial guess\n",
        "    else:\n",
        "        assert rho_init.shape == (problem_data['Ny'], problem_data['Nx'])\n",
        "    # Create loss function and optimizer\n",
        "\n",
        "    def volume_constraint_fn(rho):\n",
        "        \"\"\"Needed only for OC update\"\"\"\n",
        "        rho = rho.ravel(order='F')\n",
        "        physical_densities = apply_density_filter(rho, problem_data)\n",
        "        constraint = jnp.mean(physical_densities) - volfrac\n",
        "        return constraint\n",
        "\n",
        "    def obj_and_constraint_fn(rho):\n",
        "        rho = rho.ravel(order='F')\n",
        "        physical_densities = apply_density_filter(rho, problem_data)\n",
        "        # Compute compliance - SIMP, assemble K, Remove free DOFs, solve system\n",
        "        u_f = simp_and_reduced_solve(physical_densities, problem_data)\n",
        "        f_f = problem_data['F'][problem_data['free']]\n",
        "        compliance = u_f.T @ f_f\n",
        "        constraint = jnp.mean(physical_densities) - volfrac\n",
        "        aux_info= (compliance, constraint, physical_densities)\n",
        "        return (compliance, constraint), aux_info\n",
        "\n",
        "    # Training loop\n",
        "    objs = []\n",
        "    constraints = []\n",
        "    designs = []\n",
        "\n",
        "    rho = rho_init\n",
        "\n",
        "    for itr in range(max_iterations):\n",
        "        jacobian, aux = jax.jacrev(obj_and_constraint_fn, has_aux=True)(rho)\n",
        "        obj_grads = jacobian[0]\n",
        "        constraint_grads = jacobian[1]\n",
        "        rho = optimality_criteria(\n",
        "            rho.ravel(), obj_grads.ravel(), constraint_grads.ravel(),\n",
        "            vol_constr_fn=volume_constraint_fn)\n",
        "        obj, constr, design = aux\n",
        "        objs.append(obj)\n",
        "        constraints.append(constr)\n",
        "        designs.append(design)\n",
        "        if itr % 1 == 0:\n",
        "            print(f\"JAX - Iteration {itr}, Obj: {obj:.6f}, constr: {constr:.6f}\")\n",
        "\n",
        "    return objs, constraints, designs\n",
        "\n",
        "\n",
        "def run_with_torch_backend(problem_data, rho_init=None, max_iterations=100):\n",
        "    \"\"\"Training example with PyTorch backend\"\"\"\n",
        "    import torch\n",
        "    print(\"Training with PyTorch backend...\")\n",
        "\n",
        "    # Initialize design variables\n",
        "    if rho_init is None:\n",
        "        rho_init = torch.ones((problem_data['Ny'], problem_data['Nx'])) * volfrac  # Initial guess\n",
        "    else:\n",
        "        assert rho_init.shape == (problem_data['Ny'], problem_data['Nx'])\n",
        "    rho = rho_init.clone().requires_grad_(True)\n",
        "\n",
        "    def volume_constraint_fn(rho_np):\n",
        "        rho_torch = torch.from_numpy(rho_np)\n",
        "        rho = rho_torch.t().reshape(-1)  # equivalent to Fortran order flatten\n",
        "        # Apply filter\n",
        "        physical_densities = apply_density_filter(rho, problem_data)\n",
        "        constraint = torch.mean(physical_densities) - volfrac\n",
        "        return constraint.detach().cpu().numpy().item()\n",
        "\n",
        "    def obj_and_constraint_fn(rho):\n",
        "        rho = rho.t().reshape(-1)  # equivalent to Fortran order flatten\n",
        "        # Apply filter\n",
        "        physical_densities = apply_density_filter(rho, problem_data)\n",
        "        u_f = simp_and_reduced_solve(physical_densities, problem_data)\n",
        "        compliance = u_f @ torch.Tensor(problem_data['F'][problem_data['free']])\n",
        "        constraint = torch.mean(physical_densities) - volfrac\n",
        "        aux_info= (compliance.item(), constraint.item(), physical_densities.detach().cpu().numpy())\n",
        "        return compliance, constraint, aux_info\n",
        "\n",
        "    # Training loop\n",
        "    objs = []\n",
        "    constraints = []\n",
        "    designs = []\n",
        "\n",
        "    for itr in range(max_iterations):\n",
        "        obj, constr, aux = obj_and_constraint_fn(rho)\n",
        "\n",
        "        # Compute gradients\n",
        "        obj_grads = torch.autograd.grad(obj, rho, retain_graph=True)[0]\n",
        "        constraint_grads = torch.autograd.grad(constr, rho)[0]\n",
        "\n",
        "        # Convert to numpy (Fortran ordering)\n",
        "        rho_np = optimality_criteria(\n",
        "                rho.detach().cpu().numpy().ravel(order='F'),\n",
        "                obj_grads.detach().cpu().numpy().ravel(order='F'),\n",
        "                constraint_grads.detach().cpu().numpy().ravel(order='F'),\n",
        "                vol_constr_fn=volume_constraint_fn,\n",
        "                )\n",
        "\n",
        "        # Update rho (new leaf tensor)\n",
        "        rho = torch.from_numpy(rho_np.reshape(problem_data['Ny'], problem_data['Nx'],\n",
        "                                               order='F')).requires_grad_(True)\n",
        "\n",
        "        obj_np, constr_np, design = aux\n",
        "        objs.append(obj_np)\n",
        "        constraints.append(constr_np)\n",
        "        designs.append(design)\n",
        "\n",
        "        if itr % 1 == 0:\n",
        "            print(f\"PyTorch - Iteration {itr}, Obj: {obj_np:.6f}, constr: {constr_np:.6f}\")\n",
        "\n",
        "    return objs, constraints, designs\n",
        "\n",
        "\n",
        "    \n",
        "def run_optimization(problem_data, rho_init=None, max_iterations=100):\n",
        "    \"\"\"Train the neural network model.\"\"\"\n",
        "    backend = ML_framework_to_use\n",
        "    if backend == \"jax\":\n",
        "        return run_with_jax_backend(problem_data, rho_init=rho_init, max_iterations=max_iterations)\n",
        "    elif backend == \"torch\":\n",
        "        return run_with_torch_backend(problem_data, rho_init=rho_init, max_iterations=max_iterations)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown backend: {backend}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f832c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "problem_data = setup_fea_problem(Nx=Nx, Ny=Ny, rmin=rmin, E0=E0, Emin=Emin, penal=penal,\n",
        "                        nu=nu)\n",
        "objs, const, designs = run_optimization(problem_data, max_iterations=max_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b671cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss curve\n",
        "ax1.plot(objs,)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Compliance')\n",
        "ax1.set_title('Training Progress')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Final design\n",
        "im = ax2.imshow(designs[-1].reshape(Ny, Nx, order='F'), cmap=\"Greys\")\n",
        "ax2.set_title('Final Design')\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "ax2.axis(\"off\")\n",
        "# Attach colorbar axis with same height\n",
        "divider = make_axes_locatable(ax2)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)  # narrow, right-side\n",
        "cbar = fig.colorbar(im, cax=cax)\n",
        "\n",
        "# Formatting\n",
        "cbar.ax.tick_params(labelsize=14)\n",
        "plt.rcParams.update({\"font.sans-serif\": \"Arial\", \"font.family\": \"sans-serif\"})\n",
        "\n",
        "# Save as PDF\n",
        "fig.savefig(\"design.pdf\", bbox_inches=\"tight\", dpi=300)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0915aa0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "adto_env_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
